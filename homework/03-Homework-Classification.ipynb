{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Zoomcamp Homework 3: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mutual_info_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Download the dataset from:\n",
    "https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/course_lead_scoring.csv')\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "categorical_cols = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "numerical_cols = list(df.dtypes[df.dtypes != 'object'].index)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna('NA')\n",
    "\n",
    "for col in numerical_cols:\n",
    "    df[col] = df[col].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "What is the most frequent value in the `industry` column after handling missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Build a correlation matrix for numerical features. Which pair shows the strongest correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          number_of_courses_viewed  annual_income  \\\n",
      "number_of_courses_viewed                  1.000000       0.009770   \n",
      "annual_income                             0.009770       1.000000   \n",
      "interaction_count                        -0.023565       0.027036   \n",
      "lead_score                               -0.004879       0.015610   \n",
      "\n",
      "                          interaction_count  lead_score  \n",
      "number_of_courses_viewed          -0.023565   -0.004879  \n",
      "annual_income                      0.027036    0.015610  \n",
      "interaction_count                  1.000000    0.009888  \n",
      "lead_score                         0.009888    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Get numerical columns (excluding the target 'converted')\n",
    "numerical_features = [col for col in numerical_cols if col != 'converted']\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction_count & lead_score: 0.010\n",
      "number_of_courses_viewed & lead_score: -0.005\n",
      "number_of_courses_viewed & interaction_count: -0.024\n",
      "annual_income & interaction_count: 0.027\n"
     ]
    }
   ],
   "source": [
    "# Check specific pairs mentioned in the question\n",
    "print(f\"interaction_count & lead_score: {correlation_matrix.loc['interaction_count', 'lead_score']:.3f}\")\n",
    "print(f\"number_of_courses_viewed & lead_score: {correlation_matrix.loc['number_of_courses_viewed', 'lead_score']:.3f}\")\n",
    "print(f\"number_of_courses_viewed & interaction_count: {correlation_matrix.loc['number_of_courses_viewed', 'interaction_count']:.3f}\")\n",
    "print(f\"annual_income & interaction_count: {correlation_matrix.loc['annual_income', 'interaction_count']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Calculate mutual information scores between `converted` and categorical variables. Which categorical variable has the highest mutual information score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 876\n",
      "Validation set size: 293\n",
      "Test set size: 293\n"
     ]
    }
   ],
   "source": [
    "# Split the data first (60/20/20)\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "print(f\"Train set size: {len(df_train)}\")\n",
    "print(f\"Validation set size: {len(df_val)}\")\n",
    "print(f\"Test set size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industry: 0.01\n",
      "location: 0.0\n",
      "lead_source: 0.04\n",
      "employment_status: 0.01\n",
      "\n",
      "Highest mutual information: lead_source with score 0.04\n"
     ]
    }
   ],
   "source": [
    "# Calculate mutual information for categorical variables using training data only\n",
    "categorical_features = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "\n",
    "y_train = df_train['converted']\n",
    "\n",
    "mi_scores = {}\n",
    "for col in categorical_features:\n",
    "    mi = mutual_info_score(df_train[col], y_train)\n",
    "    mi_scores[col] = round(mi, 2)\n",
    "    print(f\"{col}: {mi_scores[col]}\")\n",
    "\n",
    "# Find the highest scoring variable\n",
    "best_feature = max(mi_scores, key=mi_scores.get)\n",
    "print(f\"\\nHighest mutual information: {best_feature} with score {mi_scores[best_feature]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Train logistic regression with one-hot encoding. What is the validation accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for training\n",
    "features = categorical_features + numerical_features\n",
    "features = [f for f in features if f != 'converted']  # Remove target if present\n",
    "\n",
    "# Convert to dictionaries for DictVectorizer\n",
    "train_dicts = df_train[features].to_dict(orient='records')\n",
    "val_dicts = df_val[features].to_dict(orient='records')\n",
    "\n",
    "# One-hot encoding\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "# Prepare target variables\n",
    "y_train = df_train['converted'].values\n",
    "y_val = df_val['converted'].values\n",
    "\n",
    "# Train logistic regression\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate validation accuracy\n",
    "y_pred_val = model.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "print(f\"Validation accuracy: {round(accuracy_val, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Perform feature elimination testing. Which feature has the smallest accuracy difference when removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.7\n",
      "Without industry: accuracy = 0.7, difference = 0.0\n",
      "Without employment_status: accuracy = 0.7, difference = 0.003\n",
      "Without lead_score: accuracy = 0.71, difference = -0.007\n",
      "\n",
      "Feature with smallest difference: lead_score (-0.007)\n"
     ]
    }
   ],
   "source": [
    "# Baseline accuracy (from Question 4)\n",
    "baseline_accuracy = accuracy_val\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")\n",
    "\n",
    "# Test features to eliminate\n",
    "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "\n",
    "accuracy_differences = {}\n",
    "\n",
    "for feature_to_remove in features_to_test:\n",
    "    # Create feature list without the current feature\n",
    "    features_subset = [f for f in features if f != feature_to_remove]\n",
    "    \n",
    "    # Convert to dictionaries\n",
    "    train_dicts_subset = df_train[features_subset].to_dict(orient='records')\n",
    "    val_dicts_subset = df_val[features_subset].to_dict(orient='records')\n",
    "    \n",
    "    # One-hot encoding\n",
    "    dv_subset = DictVectorizer(sparse=False)\n",
    "    X_train_subset = dv_subset.fit_transform(train_dicts_subset)\n",
    "    X_val_subset = dv_subset.transform(val_dicts_subset)\n",
    "    \n",
    "    # Train model\n",
    "    model_subset = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_subset.fit(X_train_subset, y_train)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    y_pred_subset = model_subset.predict(X_val_subset)\n",
    "    accuracy_subset = accuracy_score(y_val, y_pred_subset)\n",
    "    \n",
    "    # Calculate difference\n",
    "    diff = baseline_accuracy - accuracy_subset\n",
    "    accuracy_differences[feature_to_remove] = diff\n",
    "    \n",
    "    print(f\"Without {feature_to_remove}: accuracy = {round(accuracy_subset, 2)}, difference = {round(diff, 3)}\")\n",
    "\n",
    "# Find feature with smallest difference\n",
    "smallest_diff_feature = min(accuracy_differences, key=accuracy_differences.get)\n",
    "print(f\"\\nFeature with smallest difference: {smallest_diff_feature} ({round(accuracy_differences[smallest_diff_feature], 3)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Test regularization by training models with different C values. Which C produces the best validation accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01: accuracy = 0.7\n",
      "C = 0.1: accuracy = 0.7\n",
      "C = 1: accuracy = 0.7\n",
      "C = 10: accuracy = 0.7\n",
      "C = 100: accuracy = 0.7\n",
      "\n",
      "Best C value: 0.01 with accuracy 0.7\n"
     ]
    }
   ],
   "source": [
    "# Test different C values\n",
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for c in c_values:\n",
    "    # Train model with current C value\n",
    "    model_c = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "    model_c.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate validation accuracy\n",
    "    y_pred_c = model_c.predict(X_val)\n",
    "    accuracy_c = accuracy_score(y_val, y_pred_c)\n",
    "    \n",
    "    results[c] = accuracy_c\n",
    "    print(f\"C = {c}: accuracy = {round(accuracy_c, 3)}\")\n",
    "\n",
    "# Find best C value\n",
    "best_c = max(results, key=results.get)\n",
    "best_accuracy = results[best_c]\n",
    "\n",
    "# Check for ties and select smallest C if tied\n",
    "best_cs = [c for c, acc in results.items() if acc == best_accuracy]\n",
    "final_c = min(best_cs)\n",
    "\n",
    "print(f\"\\nBest C value: {final_c} with accuracy {round(best_accuracy, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
